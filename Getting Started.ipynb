{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required \n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Auto-grad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "# set requires_grad=True to track computation with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w*x+b\n",
    "y.backward() # backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)  # dy/dx = w\n",
    "print(w.grad)  # dy/dw = x\n",
    "print(b.grad)  # dy/db = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auto-grad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random vector for x and y\n",
    "x = torch.randn(10,3)\n",
    "y = torch.rand(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.2819,  0.5300, -0.2647],\n",
      "        [-0.2197,  0.4136,  0.1172]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([ 0.1443, -0.2901], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "linear =  nn.Linear(3,2) # fully connected layer\n",
    "print(\"w: \", linear.weight) # print the weight parameters\n",
    "print(\"b: \", linear.bias)   # print the bias parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # define the loss \n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr =0.01) # optimization algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = linear(x) # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.5926915407180786\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred,y) # calculate loss\n",
    "print(\"loss: \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl/dw:  tensor([[ 0.1656,  0.3095, -0.1630],\n",
      "        [ 0.4973,  0.4723,  0.0627]])\n",
      "dl/db:  tensor([-0.4414, -0.8597])\n"
     ]
    }
   ],
   "source": [
    "print(\"dl/dw: \",linear.weight.grad) # print the gradients \n",
    "print(\"dl/db: \",linear.bias.grad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # change the learned paramters using SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimizer:  0.5772436857223511\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x) # forward pass\n",
    "loss = criterion(pred,y) # find loass after one step optimization\n",
    "print(\"loss after 1 step optimizer: \", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data from numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(x)\n",
    "# Convert back to numpy\n",
    "# z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='data/data/',train=True,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset from disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from the disk\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                          batch_size=64,\n",
    "# define the iterator                                          shuffle=True)\n",
    "data_itr = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read one batch using the iterator\n",
    "images, labels = data_itr.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom dataset to load the batch easily using the train_loader\n",
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # initialize file paths or a list of the file names.\n",
    "        pass\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\"\n",
    "            Step 1: Read data from the file \n",
    "            Step 2: Transform the data point\n",
    "            Step 3: Return the data pair\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod teh custom dataset using the data loader \n",
    "custom_dataset = CustomDataSet()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the pretrain model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/vedic/.torch/models/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [00:20<00:00, 2271663.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pre-train model\n",
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the top layer for finetuning \n",
    "for par in resnet.parameters():\n",
    "    par.requires_grad = False\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random image \n",
    "images = torch.randn(64,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "# test the pretrain model on random image\n",
    "outputs = resnet(images)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model entire model\n",
    "\n",
    "torch.save(resnet,'data/models/model.ckpt')\n",
    "model = torch.load('data/models/model.ckpt')\n",
    "\n",
    "# save and load the model parameters --RECOMMENDED\n",
    "torch.save(resnet.state_dict(),'data/models/params.ckpt')\n",
    "model = resnet.load_state_dict(torch.load('data/models/params.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
